{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZDo2jRoTiT9g0bEjayUHk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
      ],
      "metadata": {
        "id": "f36YlyZlTcae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3zETgdfqKr68",
        "outputId": "afbb4db7-15a3-4c0c-9c4d-8dbbe7bcb393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('/content/gdrive/MyDrive/Machine_Learning/bigram_model/names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "YHzDGgcdVy-4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = {}\n",
        "for w in words:\n",
        "  chs = ['.'] + ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    trigram = (ch1, ch2, ch3)\n",
        "    t[trigram] = t.get(trigram, 0) + 1"
      ],
      "metadata": {
        "id": "ryMd_TAEV0mP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(t.items(), key = lambda kv: -kv[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "49kVGNc2WPdo",
        "outputId": "006a5f49-5d7c-4113-f516-3f185ff545d6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('i', 'a', '.'), 2),\n",
              " (('.', '.', 'e'), 1),\n",
              " (('.', 'e', 'm'), 1),\n",
              " (('e', 'm', 'm'), 1),\n",
              " (('m', 'm', 'a'), 1),\n",
              " (('m', 'a', '.'), 1),\n",
              " (('.', '.', 'o'), 1),\n",
              " (('.', 'o', 'l'), 1),\n",
              " (('o', 'l', 'i'), 1),\n",
              " (('l', 'i', 'v'), 1),\n",
              " (('i', 'v', 'i'), 1),\n",
              " (('v', 'i', 'a'), 1),\n",
              " (('.', '.', 'a'), 1),\n",
              " (('.', 'a', 'v'), 1),\n",
              " (('a', 'v', 'a'), 1),\n",
              " (('v', 'a', '.'), 1),\n",
              " (('.', '.', 'i'), 1),\n",
              " (('.', 'i', 's'), 1),\n",
              " (('i', 's', 'a'), 1),\n",
              " (('s', 'a', 'b'), 1),\n",
              " (('a', 'b', 'e'), 1),\n",
              " (('b', 'e', 'l'), 1),\n",
              " (('e', 'l', 'l'), 1),\n",
              " (('l', 'l', 'a'), 1),\n",
              " (('l', 'a', '.'), 1),\n",
              " (('.', '.', 's'), 1),\n",
              " (('.', 's', 'o'), 1),\n",
              " (('s', 'o', 'p'), 1),\n",
              " (('o', 'p', 'h'), 1),\n",
              " (('p', 'h', 'i'), 1),\n",
              " (('h', 'i', 'a'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "AQ5Msz_hXBmH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27, 27, 27), dtype=torch.int32)"
      ],
      "metadata": {
        "id": "jGt58yrCXljJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "vJcVmiC4YwT0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  chs = ['.'] + ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    N[ix1, ix2, ix3] += 1"
      ],
      "metadata": {
        "id": "LwSCbhzNXsY_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = (N+1).float()\n",
        "P /= P.sum(2, keepdim=True)"
      ],
      "metadata": {
        "id": "ba8PzDeGY2Bq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P.sum(2, keepdim=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r2yiUV5Qa4Wb",
        "outputId": "1ca13a8f-305b-4c4c-bc5a-708fd8d7522c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "    p = P[ix1, ix2]\n",
        "    temp = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    ix1 = temp\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JuTEUhOgbFSB",
        "outputId": "e885eeea-1c35-479d-9542-45b343f68a9c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "jakasid.\n",
            "prelay.\n",
            "adin.\n",
            "kairritoper.\n",
            "sathen.\n",
            "sameia.\n",
            "yanileniassibduinrwin.\n",
            "lessiyanayla.\n",
            "te.\n"
          ]
        }
      ]
    }
  ]
}